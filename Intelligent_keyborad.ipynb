{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def buildmodel(VOCABULARY):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(512, input_shape = (SEQ_LENGTH, 1), return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(512))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(VOCABULARY, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = open('F:\\Projects\\Intelligent keyboard\\samp_dataset.txt',encoding = 'utf8')\n",
    "raw_text = file.read()    #you need to read further characters as well\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\ufeff']\n",
      "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)\n",
    "\n",
    "bad_chars = ['#',':','\\n','\\ufeff','!','ä', 'æ', 'é', 'ë', '\"', \"'\", ':', ';', '=', '?', '[', ']', '_',  '(', ')', ',', '-', '.', ';', '=', '?', '[', ']', '_','\\n', '!', '\"', \"'\", '(', ')', ',','.', '*', '@', '†','(',')',',','-','=',']','[','!', '\"', \"'\", '(', ')', ',', ':', ';', '=', '\\n','¤', '¦', '©', '«', 'ã', '†' ' ', '!', '.', '?', '[', ']', '_','-', '.','_','?',\"'\",'\"',';',':']\n",
    "for i in range(len(bad_chars)):\n",
    "    raw_text = raw_text.replace(bad_chars[i],\"\") \n",
    "\n",
    "chars = sorted(list(set(raw_text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length = 6153\n",
      "No. of characters = 27\n"
     ]
    }
   ],
   "source": [
    "text_length = len(raw_text)\n",
    "char_length = len(chars)\n",
    "VOCABULARY = char_length\n",
    "print(\"Text length = \" + str(text_length))\n",
    "print(\"No. of characters = \" + str(char_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "input_strings = []\n",
    "output_strings = []\n",
    "\n",
    "for i in range(len(raw_text) - SEQ_LENGTH):\n",
    "    X_text = raw_text[i: i + SEQ_LENGTH]\n",
    "    X = [char_to_int[char] for char in X_text]\n",
    "    input_strings.append(X)    \n",
    "    Y = raw_text[i + SEQ_LENGTH]\n",
    "    output_strings.append(char_to_int[Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6053, 100, 1)\n",
      "(6053, 27)\n"
     ]
    }
   ],
   "source": [
    "length = len(input_strings)\n",
    "input_strings = np.array(input_strings)\n",
    "input_strings = np.reshape(input_strings, (input_strings.shape[0], input_strings.shape[1], 1))\n",
    "input_strings = input_strings/float(VOCABULARY)\n",
    "\n",
    "output_strings = np.array(output_strings)\n",
    "output_strings = to_categorical(output_strings)\n",
    "print(input_strings.shape)\n",
    "print(output_strings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildmodel(VOCABULARY)\n",
    "filepath=\"F:\\Projects\\Intelligent keyboard\\ori_dataset\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history = model.fit(input_strings, output_strings, epochs = 200, batch_size =512, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'F:\\Projects\\Intelligent keyboard\\samp_model\\weights-improvement-199-0.0006.hdf5'\n",
    "model = buildmodel(VOCABULARY)\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c268d927d248789d87bc384e5d765c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ti |  | int | much | a | loot | high | and | her | face | lightedup | at | the | thought | that | she | was | now | the | right | size | to | go | through | thesmall | door | and | get | out | to | that | lovely | gardenillustrationpoor | llcps |"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "original_text = []\n",
    "predicted_text = []\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "text = widgets.Text()\n",
    "display(text)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    global predicted_text\n",
    "    global original_text\n",
    "    \n",
    "    inp = list(text.value)\n",
    "    \n",
    "    last_word = inp[len(original_text):]\n",
    "    inp = inp[:len(original_text)]    \n",
    "    original_text = text.value    \n",
    "    last_word.append(' ')\n",
    "    \n",
    "    inp_text = [char_to_int[c] for c in inp]\n",
    "    last_word = [char_to_int[c] for c in last_word]\n",
    "    \n",
    "    if len(inp_text) > 100:\n",
    "        inp_text = inp_text[len(inp_text)-100: ]\n",
    "    if len(inp_text) < 100:\n",
    "        pad = []\n",
    "        space = char_to_int[' ']\n",
    "        pad = [space for i in range(100-len(inp_text))]\n",
    "        inp_text = pad + inp_text\n",
    "    \n",
    "    while len(last_word)>0:\n",
    "        X = np.reshape(inp_text, (1, SEQ_LENGTH, 1))\n",
    "        next_char = model.predict(X/float(VOCABULARY))\n",
    "        inp_text.append(last_word[0])\n",
    "        inp_text = inp_text[1:]\n",
    "        last_word.pop(0)\n",
    "    \n",
    "    next_word = []\n",
    "    next_char = ':'\n",
    "    while next_char != ' ':\n",
    "        X = np.reshape(inp_text, (1, SEQ_LENGTH, 1))\n",
    "        next_char = model.predict(X/float(VOCABULARY))\n",
    "        index = np.argmax(next_char)        \n",
    "        next_word.append(int_to_char[index])\n",
    "        inp_text.append(index)\n",
    "        inp_text = inp_text[1:]\n",
    "        next_char = int_to_char[index]\n",
    "    \n",
    "    predicted_text = predicted_text + [''.join(next_word)]\n",
    "    print(\" \" + ''.join(next_word), end='|')\n",
    "    \n",
    "text.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Word    Predicted Word\n",
      "-------------  ----------------------\n",
      "she\n",
      "was            ti\n",
      "now\n",
      "not            int\n",
      "quite          much\n",
      "a              a\n",
      "foot           loot\n",
      "high           high\n",
      "and            and\n",
      "her            her\n",
      "face           face\n",
      "lightedup      lightedup\n",
      "at             at\n",
      "the            the\n",
      "thought        thought\n",
      "that           that\n",
      "she            she\n",
      "was            was\n",
      "now            now\n",
      "the            the\n",
      "right          right\n",
      "size           size\n",
      "to             to\n",
      "go             go\n",
      "through        through\n",
      "thesmall       thesmall\n",
      "door           door\n",
      "and            and\n",
      "get            get\n",
      "out            out\n",
      "to             to\n",
      "that           that\n",
      "lovely         lovely\n",
      "gardern        gardenillustrationpoor\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "original_text = original_text.split()\n",
    "predicted_text.insert(0,\"\")\n",
    "predicted_text.pop()\n",
    "\n",
    "table = []\n",
    "for i in range(len(original_text)):\n",
    "    table.append([original_text[i], predicted_text[i]])\n",
    "print(tabulate(table, headers = ['Actual Word', 'Predicted Word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
